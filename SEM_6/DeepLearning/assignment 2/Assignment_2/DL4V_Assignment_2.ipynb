{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjQxSXXFhwAE"
   },
   "source": [
    "#### **Welcome to Assignment 2**\n",
    "This assignment consists of three parts. Part-1 is based on the content you learned in Week-3 of course and Part-2 is based on the content you learned in Week-4 of the course. Part-3 is **un-graded** and mainly designed to help you flex the Deep Learning muscles grown in Part-2. \n",
    "\n",
    "Unlike the first two parts, you'll have to implement everything from scratch in Part-3. If you find answers to questions in Part-3, feel free to head out to the forums and discuss them with your classmates!\n",
    "\n",
    "#### **Instructions**\n",
    "1. Use Python 3.x to run this notebook\n",
    "2. Write your code only in between the lines 'YOUR CODE STARTS HERE' and 'YOUR CODE ENDS HERE'.\n",
    "you should not change anything else in the code cells, if you do, the answers you are supposed to get at the end of this assignment might be wrong.\n",
    "3. Read documentation of each function carefully.\n",
    "4. All the Best!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jca6tcpSh0EK"
   },
   "source": [
    "# Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5KURep5V_0th"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-67929a7b1f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# %matplotlib inline uncomment this line if you're running this notebook on your local PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZEae-LT_5n-"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CODE\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSGQF0Zu9Vuo"
   },
   "source": [
    "### Question 1 : Line detection from a given image.\n",
    "\n",
    "\n",
    "Find the starting and ending point co-ordinates of detected lines of a given image (line.png) using hough transform.\n",
    "\n",
    "Following criterion need to be satisfied to qualify as a line:\n",
    "\n",
    "(a) Minimum line length = 60;\n",
    "(b) Maximum allowed gap between line segments = 250;\n",
    "(c) Accumulator threshold parameter = 15  (only those lines are returned that get enough votes);\n",
    "(d) Distance resolution of the accumulator in pixels = 1;\n",
    "(e) Angle resolution of the accumulator in radians = pi/180\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwdLOgZs99bC"
   },
   "outputs": [],
   "source": [
    "#Read image \n",
    "img = cv2.imread('line.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Visualize the input image\n",
    "plt.imshow(img)\n",
    "plt.title('Input Image')\n",
    "plt.show()\n",
    "\n",
    "#### YOUR CODE STARTS HERE #####\n",
    "#convert the image to gray-scale\n",
    "gray = \n",
    "#### YOUR CODE ENDS HERE #####\n",
    "\n",
    "#Find the edges in the image using canny detector\n",
    "\n",
    "edges = cv2.Canny(gray, 50, 200)\n",
    "\n",
    "#### YOUR CODE STARTS HERE #####\n",
    "\n",
    "\n",
    "#### YOUR CODE ENDS HERE #####\n",
    "plt.imshow(img)\n",
    "plt.title('Detected Line Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhErU_TY-PpU"
   },
   "source": [
    "##Question 2: Point matching using RANSAC\n",
    "\n",
    "Given two sets of points related by affine transformation(with an outlier rate), use the RANSAC method to estimate the Affine transformation parameters between them and the number of inliers(Matching points).\n",
    "\n",
    "What is the estimated number of inliers for an outlier rate of 0.9?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYotkDxG-kkP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# Affine Transformation\n",
    "# |x'|  = |a, b| * |x|  +  |tx|\n",
    "# |y'|    |c, d|   |y|     |ty|\n",
    "# points_t =    A   * points_s  + t\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "class Transform():\n",
    "\n",
    "    def create_case(self, out_rate):\n",
    "        ''' CREATE_CASE\n",
    "\n",
    "            Method to generate a test case for affine transformation\n",
    "\n",
    "            Input arguments:\n",
    "            - out_rate : the percentage of outliers in test case\n",
    "\n",
    "            Outputs:\n",
    "            - points_s : Source points that will be transformed\n",
    "            - points_t : warped points\n",
    "            - A, t : parameters of affine transformation, A is a 2x2\n",
    "            matrix, t is a 2x1 vector, both of them are created randomly\n",
    "\n",
    "        '''\n",
    "\n",
    "\n",
    "        # Generate an affine transformation\n",
    "        # A is a 2x2 matrix, with values in range -2 to 2\n",
    "        A = 4 * np.random.rand(2, 2) - 2\n",
    "\n",
    "        # t is a 2x1 vector, with values in range -10 to 10\n",
    "        t = 20 * np.random.rand(2, 1) - 10\n",
    "\n",
    "        # Set the num_points = 1000 for the test case\n",
    "        num_points = 1000\n",
    "\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # Compute the no. of outliers and the no. of inliers respectively\n",
    "        outliers = \n",
    "        inliers = \n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "\n",
    "        # Gernerate source points, with scope from (0,0) to (100, 100)\n",
    "        points_s = 100 * np.random.rand(2, num_points)\n",
    "\n",
    "        # Initialization of the warped points matrix\n",
    "        points_t = np.zeros((2, num_points))\n",
    "\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # Compute inliers in warped points matrix by applying A and t\n",
    "        points_t[:, :inliers] = \n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "\n",
    "        # Outliers in warped points matrix\n",
    "        points_t[:, inliers:] = 100 * np.random.rand(2, outliers)\n",
    "\n",
    "        # Reset the order of warped points matrix\n",
    "        # outliers and inliers will scatter randomly in test case\n",
    "        rand_inx = np.random.permutation(num_points)\n",
    "        points_s = points_s[:, rand_inx]\n",
    "        points_t = points_t[:, rand_inx]\n",
    "\n",
    "        return A, t, points_s, points_t\n",
    "\n",
    "    def affine_transformation(self, points_s, points_t):  \n",
    "        ''' AFFINE_TRANSFORMATION\n",
    "\n",
    "            Perform affine transformation\n",
    "\n",
    "            Input arguments:\n",
    "            - points_t : points in target image\n",
    "            - points_s : points in source image\n",
    "\n",
    "            Outputs:\n",
    "\n",
    "            - A, t : the affine transformation, A is a 2x2 matrix\n",
    "            that indicates the rotation and scaling transformation,\n",
    "            t is a 2x1 vector determines the translation\n",
    "\n",
    "            Method:\n",
    "\n",
    "            To estimate an affine transformation between two images,\n",
    "            at least 3 corresponding points are needed.\n",
    "            In this case, 6-parameter affine transformation are taken into\n",
    "            consideration, which is shown as follows:\n",
    "\n",
    "            | x' | = | a b | * | x | + | tx |\n",
    "            | y' |   | c d |   | y |   | ty |\n",
    "\n",
    "            For 3 corresponding points, 6 equations can be formed as below:\n",
    "\n",
    "            | x1 y1 0  0  1 0 |       | a  |       | x1' |\n",
    "            | 0  0  x1 y1 0 1 |       | b  |       | y1' |\n",
    "            | x2 y2 0  0  1 0 |   *   | c  |   =   | x2' |\n",
    "            | 0  0  x2 y2 0 1 |       | d  |       | y2' |\n",
    "            | x3 y3 0  0  1 0 |       | tx |       | x3' |\n",
    "            | 0  0  x3 y3 0 1 |       | ty |       | y3' |\n",
    "\n",
    "            |------> M <------|   |-> theta <-|   |-> b <-|\n",
    "\n",
    "            Solve the equation by calculating:  theta = M \\ b\n",
    "            Thus, affine transformation can be obtained as:\n",
    "\n",
    "            A = | a b |     t = | tx |\n",
    "                | c d |         | ty |\n",
    "\n",
    "        '''\n",
    "\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        \n",
    "\n",
    "\n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Create instance\n",
    "tf = Transform()\n",
    "\n",
    "# Generate a test case as validation with\n",
    "# a rate of outliers\n",
    "out_rate = 0.90\n",
    "A_true, t_true, points_s, points_t = tf.create_case(out_rate)\n",
    "\n",
    "# At least 3 corresponding points to\n",
    "# estimate affine transformation\n",
    "L = 3\n",
    "# Randomly select 3 pairs of points to do estimation\n",
    "idx = np.random.randint(0, points_s.shape[1], (L, 1))\n",
    "\n",
    "A_test, t_test = tf.affine_transformation(points_s[:, idx], points_t[:, idx])\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Test Class RansacClass\n",
    "# The number of iterations in RANSAC\n",
    "ITER_NUM = 2000\n",
    "\n",
    "\n",
    "class RansacClass():\n",
    "\n",
    "    def __init__(self, L=3, thr=1): \n",
    "        ''' __INIT__\n",
    "\n",
    "            Initialize the instance.\n",
    "\n",
    "            Input arguments:\n",
    "\n",
    "            - L : the number of corresponding points,\n",
    "            default is 3\n",
    "            - thr : threshold that determines which points are inliers\n",
    "            by comparing residual with it\n",
    "\n",
    "        '''\n",
    "\n",
    "        self.L = L\n",
    "        self.thr = thr\n",
    "\n",
    "    def calculate_distance(self, A, t, points_s, points_t):     \n",
    "        ''' CALCULATE_DISTANCE\n",
    "\n",
    "            Compute residual length between estimation and \n",
    "            real target points.\n",
    " \n",
    "\n",
    "            Input arguments:\n",
    "\n",
    "            - A, t : the estimated affine transformation\n",
    "                     (using least square)\n",
    "            - points_s : key points taken from source image\n",
    "            - points_t : key points taken from target image\n",
    "\n",
    "            Output:\n",
    "\n",
    "            - residual : Euclidean distance between target \n",
    "            points and estimated points. Euclidean distance is\n",
    "            nothing but the residual length\n",
    "\n",
    "        '''\n",
    "\n",
    "        ###YOUR CODE START HERE\n",
    "\n",
    "\n",
    "\n",
    "        ###YOUR CODE ENDS HERE\n",
    "\n",
    "    def apply_ransac(self, points_s, points_t):\n",
    "        ''' APPLY_RANSAC\n",
    "\n",
    "            Use this method to get the estimateda ffine \n",
    "            transformation, also inliers.\n",
    "\n",
    "            Input arguments:\n",
    "\n",
    "            - points_s : key points from source image\n",
    "            - points_t : key points from target image\n",
    "\n",
    "            Output:\n",
    "\n",
    "            - A, t : estimated affine transformation\n",
    "            - inliers : indices of inliers \n",
    "\n",
    "        '''\n",
    "        #### YOUR CODE START HERE\n",
    "\n",
    "\n",
    "        \n",
    "        #### YOUR CODE ENDS HERE\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Create instance\n",
    "rs = RansacClass(L=3, thr=1)\n",
    "\n",
    "residual = rs.calculate_distance(A_test, t_test, points_s, points_t)\n",
    "A_rsc, t_rsc, inliers = rs.apply_ransac(points_s, points_t)\n",
    "\n",
    "# print the number of inliners or point matches\n",
    "print(inliers[0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnf_pn2N-vS7"
   },
   "source": [
    "### Question 3: Detect corners in a given image using Harris Corner Detection Algorithm\n",
    "\n",
    "Find the number of detected corner points in a given image (line.png) using Harris Corner Detection Algorithm. Note that, Following criterion MUST be satisfied while applying Harris Corner detection Algorithm:\n",
    "\n",
    "(a)  The size of neighbourhood considered for corner detection = 2.\n",
    "(b)  Aperture parameter of Sobel derivative used = 3.\n",
    "(c)  Harris detector free parameter in the equation = 0.04.\n",
    "\n",
    "How many corners are detected?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQSynG8c-0y4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the image\n",
    "image = cv2.imread('line.png')\n",
    "\n",
    "# Make a copy of the image\n",
    "image_copy = np.copy(image)\n",
    "\n",
    "# Change color to RGB (from BGR)\n",
    "image_copy = cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "###YOUR CODE STARTS HERE\n",
    "\n",
    "## STEP 1:  Convert to grayscale \n",
    "\n",
    "## STEP 2: Detect corners \n",
    "\n",
    "## STEP 3: Dilate corner image to enhance corner points\n",
    "\n",
    "## STEP 4:set threshold value as 0.1 * (maximum value of dilated corner image obtained from STEP3)\n",
    "\n",
    "## STEP 5: Count numer of detected corner points and draw them on the image\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXrQtCnwhz5J"
   },
   "source": [
    "# Part-2\n",
    "\n",
    "In this section, we will train a neural network to learn to identify numerals from [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. Fill out the missing pieces in each of the following cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVEgO_bNhLtx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import timeit\n",
    "import unittest\n",
    "\n",
    "## Please DONOT remove these lines. \n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mc4Nl4gCLyiN"
   },
   "source": [
    "### Data Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECXvC1tUhpPA"
   },
   "outputs": [],
   "source": [
    "# check availability of GPU and set the device accordingly\n",
    "#### YOUR CODE STARTS HERE ####\n",
    "device = \n",
    "\n",
    "# define a transforms for preparing the dataset\n",
    "transform = \n",
    "         # convert the image to a pytorch tensor\n",
    "        # normalise the images with mean (0.1307) and std (0.3081) of the dataset\n",
    "#### YOUR CODE ENDS HERE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e88bU4vhtdG"
   },
   "outputs": [],
   "source": [
    "# Load the MNIST training, test datasets using `torchvision.datasets.MNIST` using the transform defined above\n",
    "#### YOUR CODE STARTS HERE ####\n",
    "train_dataset = \n",
    "test_dataset = \n",
    "#### YOUR CODE ENDS HERE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2eBGz9OhvD1"
   },
   "outputs": [],
   "source": [
    "# create dataloaders for training and test datasets\n",
    "# use a batch size of 32 and set shuffle=True for the training set\n",
    "#### YOUR CODE STARTS HERE ####\n",
    "train_dataloader = \n",
    "test_dataloader = \n",
    "#### YOUR CODE ENDS HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFfzN-oaL762"
   },
   "source": [
    "### Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPQMmDKbhwy9"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # define a conv layer with output channels as 16, kernel size of 3 and stride of 1\n",
    "\n",
    "        # define a conv layer with output channels as 32, kernel size of 3 and stride of 1\n",
    "        \n",
    "        # define a conv layer with output channels as 64, kernel size of 3 and stride of 1\n",
    "\n",
    "        # define a max pooling layer with kernel size 2\n",
    "        \n",
    "        # define dropout layer with a probability of 0.25\n",
    "        \n",
    "        # define dropout layer with a probability of 0.5\n",
    "        \n",
    "        # define a linear(dense) layer with 128 output features\n",
    "        \n",
    "        # define a linear(dense) layer with output features corresponding to the number of classes in the dataset\n",
    "        \n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the layers defined above in a sequential way (folow the same as the layer definitions above) and \n",
    "        # write the forward pass, after each of conv1, conv2, conv3 and fc1 use a relu activation. \n",
    "        # use the first dropout after maxpool and the other one before you final FC layer\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        out\n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "        output = F.log_softmax(out, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_8IZKqGiAhM"
   },
   "source": [
    "### Sanity Check\n",
    "Make sure all the tests below pass without any errors, before you proceed with the training part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAiwx-TSyPK6"
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestImplementations(unittest.TestCase):\n",
    "    \n",
    "    # Dataloading tests\n",
    "    def test_dataset(self):\n",
    "        self.dataset_classes = ['0 - zero',\n",
    "                                '1 - one',\n",
    "                                '2 - two',\n",
    "                                '3 - three',\n",
    "                                '4 - four',\n",
    "                                '5 - five',\n",
    "                                '6 - six',\n",
    "                                '7 - seven',\n",
    "                                '8 - eight',\n",
    "                                '9 - nine']\n",
    "        self.assertTrue(train_dataset.classes == self.dataset_classes)\n",
    "        self.assertTrue(train_dataset.train == True)\n",
    "    \n",
    "    def test_dataloader(self):        \n",
    "        self.assertTrue(train_dataloader.batch_size == 32)\n",
    "        self.assertTrue(test_dataloader.batch_size == 32)      \n",
    "         \n",
    "    def test_total_parameters(self):\n",
    "        model = Net().to(device)\n",
    "        self.assertTrue(sum(p.numel() for p in model.parameters()) == 1015946)\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromModule(TestImplementations())\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GkrWn_dfVyo"
   },
   "source": [
    "### Training and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIdgIfkAGXi9"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "      #### YOUR CODE STARTS HERE ####\n",
    "        # send the image, target to the device\n",
    "        \n",
    "        # flush out the gradients stored in optimizer\n",
    "\n",
    "        # pass the image to the model and assign the output to variable named output\n",
    "        \n",
    "        # calculate the loss (use nll_loss in pytorch)\n",
    "        \n",
    "        # do a backward pass\n",
    "        \n",
    "        # update the weights\n",
    "        \n",
    "      #### YOUR CODE ENDS HERE ####\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWEpNBtdHVWr"
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "          ### YOUR CODE STARTS HERE ####\n",
    "            # send the image, target to the device\n",
    "            \n",
    "            # pass the image to the model and assign the output to variable named output\n",
    "            \n",
    "            test_loss += # sum up batch loss\n",
    "          #### YOUR CODE ENDS HERE ####\n",
    "            # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m02MLg2mxRwB"
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Use Adam as the optimiser and train the model for 25 epochs. Report the train, test loss and accuracies along with the total time taken for training. (Use plots if required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TV3DSN3v0NBN"
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Modify the network defined in the previous step to replace ReLU activations with Sigmoid and report the final test accuracy. Is there a drop in accuracy, what do you think is the reason? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lurbs-F35AqX"
   },
   "source": [
    "### Question 6\n",
    "\n",
    "Train the network defined in Question-1 with a different optimiser other than Adam, do you see any difference in performance? Substantiate your observations with relevant explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m34pGNerYmld"
   },
   "source": [
    "### Question 7\n",
    "\n",
    "Initialize the `Conv2d` layers in the network defined in Question-1 `(Net)` with all ones (both weights and bias). Train the network with Adam optimizer and report the final test accuracy. Is there any difference in the performance? If yes, what do you think is the reason? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHmX6YO_ay9n"
   },
   "source": [
    "### Question 8\n",
    "\n",
    "Initialize the network defined in Question-1 `(Net)` with Xavier's initialization ([torch.nn.init.xavier_normal](https://pytorch.org/docs/stable/nn.init.html))(for bias use zero). Train the network with Adam optimizer and report the final test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3OqBlnPe4LR"
   },
   "source": [
    "### Question 9\n",
    "\n",
    "Add three batch-norm layers to the network defined in `Question-1` and report the final test accuracy. How does batch-norm help? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLjR0rM3nFnq"
   },
   "source": [
    "# Part-3 (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxogDSnVqcjO"
   },
   "source": [
    "This section is un-graded and purely for practice. \n",
    "\n",
    "Main focus of this part is to help you flex the deep learning muscles built in the above part. You should build a network on the [SVHN dataset](http://ufldl.stanford.edu/housenumbers/). This dataset is similar to MNIST but unlike MNIST, the images are colored and more complex. \n",
    "\n",
    "As of writing this, the state-of-the-art(SoTA) performance on this dataset is 98.98%. You can try to start with the simple network we defined above for the MNSIT dataset(with some modification for dealing with different sized colored images unlike MNIST). But to achive the SoTA performance you need to do a lot of hackery. These are list of few things, we would encourage you to try: \n",
    "\n",
    "- Use data augmentation wisely. Read and understand how to perform the augmentations listed below. \n",
    "    * RandomFlips, Color Jittering\n",
    "    * Cutout, Cutmix\n",
    "    * Mixup\n",
    "    * Auto-augment\n",
    "\n",
    "- Try to increase the image size using standard image interpolation techniques. Try using tricks like Progressive resizing of images and see if it helps. \n",
    "\n",
    "- After certain number of layers, adding more layer might not be of much help, run experiments on SVHN and see if you observe this. \n",
    "\n",
    "- To understand the difficulties in training deeper networks read this paper: [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "- To improve the performance on SVHN, try using architectures like [ResNet](https://arxiv.org/abs/1512.03385), [DesnseNet](https://arxiv.org/abs/1608.06993) or [EfficientNet](https://arxiv.org/abs/1905.11946). Most of these architectures are available by default in PyTorch.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "uLjR0rM3nFnq"
   ],
   "name": "DL4V_Assignment_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
